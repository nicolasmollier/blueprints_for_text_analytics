{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c35fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 20:37:43.141703: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:43.141736: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-08 20:37:45.024774: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-08 20:37:45.025490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-08 20:37:45.026449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-08 20:37:45.026918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.875GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2023-01-08 20:37:45.027030: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:45.027116: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:45.027183: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:45.027220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-08 20:37:45.027244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-08 20:37:45.027268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-08 20:37:45.027325: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:45.027389: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:45.027398: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "import re\n",
    "import html\n",
    "import textacy.preprocessing as tprep\n",
    "from textacy.preprocessing.resources import RE_URL\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6d204",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759afbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../blueprints-text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3250eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abbd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.blueprints.exploration import count_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960628c",
   "metadata": {},
   "source": [
    "### 1.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540fa0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv(os.path.join(data_path, \"reddit-selfposts/rspct_autos.tsv.gz\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aadfd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5s0q8r</td>\n",
       "      <td>Mustang</td>\n",
       "      <td>Roush vs Shleby GT500</td>\n",
       "      <td>I am trying to determine which is faster, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5z3405</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2001 Golf Wagon looking for some insight</td>\n",
       "      <td>Hello! &lt;lb&gt;&lt;lb&gt;Trying to find some information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7df18v</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>IS 250 Coolant Flush/Change</td>\n",
       "      <td>https://www.cars.com/articles/how-often-should...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5tpve8</td>\n",
       "      <td>volt</td>\n",
       "      <td>Gen1 mpg w/ dead battery?</td>\n",
       "      <td>Hi, new to this subreddit.  I'm considering bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>7i2k6y</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Bilstein Shocks</td>\n",
       "      <td>I read a lot Forums and people recommend getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>83p2kv</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Question on potential purchase of crashed bike.</td>\n",
       "      <td>I am thinking about  buying a 2010 Harley Spor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>7x722h</td>\n",
       "      <td>volt</td>\n",
       "      <td>Got our first warning light on our dash</td>\n",
       "      <td>My husband and I were headed somewhere and I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>7v2xmg</td>\n",
       "      <td>Lexus</td>\n",
       "      <td>Any IS models to avoid?</td>\n",
       "      <td>I am looking at getting a used Lexus IS (2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>8dxx3b</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>Advice please. Looking at a 2011 E550 with 71K...</td>\n",
       "      <td>Looking for some help. I've never owned any lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      subreddit  \\\n",
       "0      8f73s7         Harley   \n",
       "1      5s0q8r        Mustang   \n",
       "2      5z3405     Volkswagen   \n",
       "3      7df18v          Lexus   \n",
       "4      5tpve8           volt   \n",
       "...       ...            ...   \n",
       "19995  7i2k6y        4Runner   \n",
       "19996  83p2kv         Harley   \n",
       "19997  7x722h           volt   \n",
       "19998  7v2xmg          Lexus   \n",
       "19999  8dxx3b  mercedes_benz   \n",
       "\n",
       "                                                   title  \\\n",
       "0                                         No Club Colors   \n",
       "1                                  Roush vs Shleby GT500   \n",
       "2               2001 Golf Wagon looking for some insight   \n",
       "3                            IS 250 Coolant Flush/Change   \n",
       "4                              Gen1 mpg w/ dead battery?   \n",
       "...                                                  ...   \n",
       "19995                                    Bilstein Shocks   \n",
       "19996    Question on potential purchase of crashed bike.   \n",
       "19997            Got our first warning light on our dash   \n",
       "19998                            Any IS models to avoid?   \n",
       "19999  Advice please. Looking at a 2011 E550 with 71K...   \n",
       "\n",
       "                                                selftext  \n",
       "0      Funny story. I went to college in Las Vegas. T...  \n",
       "1      I am trying to determine which is faster, and ...  \n",
       "2      Hello! <lb><lb>Trying to find some information...  \n",
       "3      https://www.cars.com/articles/how-often-should...  \n",
       "4      Hi, new to this subreddit.  I'm considering bu...  \n",
       "...                                                  ...  \n",
       "19995  I read a lot Forums and people recommend getti...  \n",
       "19996  I am thinking about  buying a 2010 Harley Spor...  \n",
       "19997  My husband and I were headed somewhere and I w...  \n",
       "19998  I am looking at getting a used Lexus IS (2014 ...  \n",
       "19999  Looking for some help. I've never owned any lu...  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30233709",
   "metadata": {},
   "outputs": [],
   "source": [
    "subred_df = pd.read_csv(os.path.join(data_path, \"reddit-selfposts/subreddit_info.csv.gz\")).set_index([\"subreddit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f6c27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>in_data</th>\n",
       "      <th>reason_for_exclusion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whatsthatbook</th>\n",
       "      <td>advice/question</td>\n",
       "      <td>book</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CasualConversation</th>\n",
       "      <td>advice/question</td>\n",
       "      <td>broad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>too_broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clairvoyantreadings</th>\n",
       "      <td>advice/question</td>\n",
       "      <td>broad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>too_broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecidingToBeBetter</th>\n",
       "      <td>advice/question</td>\n",
       "      <td>broad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>too_broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HelpMeFind</th>\n",
       "      <td>advice/question</td>\n",
       "      <td>broad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>too_broad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HFY</th>\n",
       "      <td>writing/stories</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TalesFromYourServer</th>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>fewer posts than r/talesfromtechsupport which ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talesfromtechsupport</th>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WayfarersPub</th>\n",
       "      <td>writing/stories</td>\n",
       "      <td>wayfarers pub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glitch_in_the_Matrix</th>\n",
       "      <td>writing/stories</td>\n",
       "      <td>weird</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>too_broad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3394 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category_1     category_2 category_3  in_data  \\\n",
       "subreddit                                                                  \n",
       "whatsthatbook         advice/question           book        NaN     True   \n",
       "CasualConversation    advice/question          broad        NaN    False   \n",
       "Clairvoyantreadings   advice/question          broad        NaN    False   \n",
       "DecidingToBeBetter    advice/question          broad        NaN    False   \n",
       "HelpMeFind            advice/question          broad        NaN    False   \n",
       "...                               ...            ...        ...      ...   \n",
       "HFY                   writing/stories         sci-fi        NaN     True   \n",
       "TalesFromYourServer   writing/stories   tech support        NaN    False   \n",
       "talesfromtechsupport  writing/stories   tech support        NaN     True   \n",
       "WayfarersPub          writing/stories  wayfarers pub        NaN     True   \n",
       "Glitch_in_the_Matrix  writing/stories          weird        NaN    False   \n",
       "\n",
       "                                                   reason_for_exclusion  \n",
       "subreddit                                                                \n",
       "whatsthatbook                                                       NaN  \n",
       "CasualConversation                                            too_broad  \n",
       "Clairvoyantreadings                                           too_broad  \n",
       "DecidingToBeBetter                                            too_broad  \n",
       "HelpMeFind                                                    too_broad  \n",
       "...                                                                 ...  \n",
       "HFY                                                                 NaN  \n",
       "TalesFromYourServer   fewer posts than r/talesfromtechsupport which ...  \n",
       "talesfromtechsupport                                                NaN  \n",
       "WayfarersPub                                                        NaN  \n",
       "Glitch_in_the_Matrix                                          too_broad  \n",
       "\n",
       "[3394 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011aad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(posts_df, subred_df, on=\"subreddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8db7990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>in_data</th>\n",
       "      <th>reason_for_exclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4z6vee</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Mystery Rattle</td>\n",
       "      <td>I have a stock 2010 FXD that has a rate I can'...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6x4tdk</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Gum on tailpipe</td>\n",
       "      <td>So I'm on a bike trip with my father and we st...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7l7rer</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Changing up the bars!</td>\n",
       "      <td>So I’m gonna change out my T bars that came on...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683pc7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Spent 2 days and made some Mini Floorboards fo...</td>\n",
       "      <td>A few weeks ago, somebody was looking for some...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>7346dx</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>03 JBL Sound System Issue</td>\n",
       "      <td>Just picked up my first 4Runner this week! Lov...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>5ut9e2</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>2nd gen Comes Back From the Dead With No Tools</td>\n",
       "      <td>Hello fellow runners-&lt;lb&gt;&lt;lb&gt;I wanted to share...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>66xnwd</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Tranny cooler in cold temperatures?</td>\n",
       "      <td>So I picked up a 2002 4Runner recently and the...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>8kvxkg</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Torn between a Wrangler and a 4 Runner...</td>\n",
       "      <td>Ok so I've posted to r/Jeep and figured I shou...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>7i2k6y</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Bilstein Shocks</td>\n",
       "      <td>I read a lot Forums and people recommend getti...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id subreddit                                              title  \\\n",
       "0      8f73s7    Harley                                     No Club Colors   \n",
       "1      4z6vee    Harley                                     Mystery Rattle   \n",
       "2      6x4tdk    Harley                                    Gum on tailpipe   \n",
       "3      7l7rer    Harley                              Changing up the bars!   \n",
       "4      683pc7    Harley  Spent 2 days and made some Mini Floorboards fo...   \n",
       "...       ...       ...                                                ...   \n",
       "19995  7346dx   4Runner                          03 JBL Sound System Issue   \n",
       "19996  5ut9e2   4Runner     2nd gen Comes Back From the Dead With No Tools   \n",
       "19997  66xnwd   4Runner                Tranny cooler in cold temperatures?   \n",
       "19998  8kvxkg   4Runner          Torn between a Wrangler and a 4 Runner...   \n",
       "19999  7i2k6y   4Runner                                    Bilstein Shocks   \n",
       "\n",
       "                                                selftext category_1  \\\n",
       "0      Funny story. I went to college in Las Vegas. T...      autos   \n",
       "1      I have a stock 2010 FXD that has a rate I can'...      autos   \n",
       "2      So I'm on a bike trip with my father and we st...      autos   \n",
       "3      So I’m gonna change out my T bars that came on...      autos   \n",
       "4      A few weeks ago, somebody was looking for some...      autos   \n",
       "...                                                  ...        ...   \n",
       "19995  Just picked up my first 4Runner this week! Lov...      autos   \n",
       "19996  Hello fellow runners-<lb><lb>I wanted to share...      autos   \n",
       "19997  So I picked up a 2002 4Runner recently and the...      autos   \n",
       "19998  Ok so I've posted to r/Jeep and figured I shou...      autos   \n",
       "19999  I read a lot Forums and people recommend getti...      autos   \n",
       "\n",
       "            category_2 category_3  in_data reason_for_exclusion  \n",
       "0      harley davidson        NaN     True                  NaN  \n",
       "1      harley davidson        NaN     True                  NaN  \n",
       "2      harley davidson        NaN     True                  NaN  \n",
       "3      harley davidson        NaN     True                  NaN  \n",
       "4      harley davidson        NaN     True                  NaN  \n",
       "...                ...        ...      ...                  ...  \n",
       "19995           toyota        NaN     True                  NaN  \n",
       "19996           toyota        NaN     True                  NaN  \n",
       "19997           toyota        NaN     True                  NaN  \n",
       "19998           toyota        NaN     True                  NaN  \n",
       "19999           toyota        NaN     True                  NaN  \n",
       "\n",
       "[20000 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc441169",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'subreddit': 'subreddit',\n",
    "    'title': 'title',\n",
    "    'selftext': 'text',\n",
    "    'category_1': 'category',\n",
    "    'category_2': 'subcategory',\n",
    "    'category_3': None,\n",
    "    'in_data': None,\n",
    "    'reason_for_exclusion': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3011f392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'subreddit', 'title', 'selftext', 'category_1', 'category_2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [c for c in column_mapping.keys() if column_mapping[c] != None]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fb95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4z6vee</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Mystery Rattle</td>\n",
       "      <td>I have a stock 2010 FXD that has a rate I can'...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6x4tdk</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Gum on tailpipe</td>\n",
       "      <td>So I'm on a bike trip with my father and we st...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7l7rer</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Changing up the bars!</td>\n",
       "      <td>So I’m gonna change out my T bars that came on...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683pc7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Spent 2 days and made some Mini Floorboards fo...</td>\n",
       "      <td>A few weeks ago, somebody was looking for some...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>7346dx</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>03 JBL Sound System Issue</td>\n",
       "      <td>Just picked up my first 4Runner this week! Lov...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>5ut9e2</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>2nd gen Comes Back From the Dead With No Tools</td>\n",
       "      <td>Hello fellow runners-&lt;lb&gt;&lt;lb&gt;I wanted to share...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>66xnwd</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Tranny cooler in cold temperatures?</td>\n",
       "      <td>So I picked up a 2002 4Runner recently and the...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>8kvxkg</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Torn between a Wrangler and a 4 Runner...</td>\n",
       "      <td>Ok so I've posted to r/Jeep and figured I shou...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>7i2k6y</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Bilstein Shocks</td>\n",
       "      <td>I read a lot Forums and people recommend getti...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id subreddit                                              title  \\\n",
       "0      8f73s7    Harley                                     No Club Colors   \n",
       "1      4z6vee    Harley                                     Mystery Rattle   \n",
       "2      6x4tdk    Harley                                    Gum on tailpipe   \n",
       "3      7l7rer    Harley                              Changing up the bars!   \n",
       "4      683pc7    Harley  Spent 2 days and made some Mini Floorboards fo...   \n",
       "...       ...       ...                                                ...   \n",
       "19995  7346dx   4Runner                          03 JBL Sound System Issue   \n",
       "19996  5ut9e2   4Runner     2nd gen Comes Back From the Dead With No Tools   \n",
       "19997  66xnwd   4Runner                Tranny cooler in cold temperatures?   \n",
       "19998  8kvxkg   4Runner          Torn between a Wrangler and a 4 Runner...   \n",
       "19999  7i2k6y   4Runner                                    Bilstein Shocks   \n",
       "\n",
       "                                                    text category  \\\n",
       "0      Funny story. I went to college in Las Vegas. T...    autos   \n",
       "1      I have a stock 2010 FXD that has a rate I can'...    autos   \n",
       "2      So I'm on a bike trip with my father and we st...    autos   \n",
       "3      So I’m gonna change out my T bars that came on...    autos   \n",
       "4      A few weeks ago, somebody was looking for some...    autos   \n",
       "...                                                  ...      ...   \n",
       "19995  Just picked up my first 4Runner this week! Lov...    autos   \n",
       "19996  Hello fellow runners-<lb><lb>I wanted to share...    autos   \n",
       "19997  So I picked up a 2002 4Runner recently and the...    autos   \n",
       "19998  Ok so I've posted to r/Jeep and figured I shou...    autos   \n",
       "19999  I read a lot Forums and people recommend getti...    autos   \n",
       "\n",
       "           subcategory  \n",
       "0      harley davidson  \n",
       "1      harley davidson  \n",
       "2      harley davidson  \n",
       "3      harley davidson  \n",
       "4      harley davidson  \n",
       "...                ...  \n",
       "19995           toyota  \n",
       "19996           toyota  \n",
       "19997           toyota  \n",
       "19998           toyota  \n",
       "19999           toyota  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[columns].rename(columns=column_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab50978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4z6vee</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Mystery Rattle</td>\n",
       "      <td>I have a stock 2010 FXD that has a rate I can'...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6x4tdk</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Gum on tailpipe</td>\n",
       "      <td>So I'm on a bike trip with my father and we st...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7l7rer</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Changing up the bars!</td>\n",
       "      <td>So I’m gonna change out my T bars that came on...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>683pc7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>Spent 2 days and made some Mini Floorboards fo...</td>\n",
       "      <td>A few weeks ago, somebody was looking for some...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>7346dx</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>03 JBL Sound System Issue</td>\n",
       "      <td>Just picked up my first 4Runner this week! Lov...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>5ut9e2</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>2nd gen Comes Back From the Dead With No Tools</td>\n",
       "      <td>Hello fellow runners-&lt;lb&gt;&lt;lb&gt;I wanted to share...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>66xnwd</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Tranny cooler in cold temperatures?</td>\n",
       "      <td>So I picked up a 2002 4Runner recently and the...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>8kvxkg</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Torn between a Wrangler and a 4 Runner...</td>\n",
       "      <td>Ok so I've posted to r/Jeep and figured I shou...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>7i2k6y</td>\n",
       "      <td>4Runner</td>\n",
       "      <td>Bilstein Shocks</td>\n",
       "      <td>I read a lot Forums and people recommend getti...</td>\n",
       "      <td>autos</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id subreddit                                              title  \\\n",
       "0      8f73s7    Harley                                     No Club Colors   \n",
       "1      4z6vee    Harley                                     Mystery Rattle   \n",
       "2      6x4tdk    Harley                                    Gum on tailpipe   \n",
       "3      7l7rer    Harley                              Changing up the bars!   \n",
       "4      683pc7    Harley  Spent 2 days and made some Mini Floorboards fo...   \n",
       "...       ...       ...                                                ...   \n",
       "19995  7346dx   4Runner                          03 JBL Sound System Issue   \n",
       "19996  5ut9e2   4Runner     2nd gen Comes Back From the Dead With No Tools   \n",
       "19997  66xnwd   4Runner                Tranny cooler in cold temperatures?   \n",
       "19998  8kvxkg   4Runner          Torn between a Wrangler and a 4 Runner...   \n",
       "19999  7i2k6y   4Runner                                    Bilstein Shocks   \n",
       "\n",
       "                                                    text category  \\\n",
       "0      Funny story. I went to college in Las Vegas. T...    autos   \n",
       "1      I have a stock 2010 FXD that has a rate I can'...    autos   \n",
       "2      So I'm on a bike trip with my father and we st...    autos   \n",
       "3      So I’m gonna change out my T bars that came on...    autos   \n",
       "4      A few weeks ago, somebody was looking for some...    autos   \n",
       "...                                                  ...      ...   \n",
       "19995  Just picked up my first 4Runner this week! Lov...    autos   \n",
       "19996  Hello fellow runners-<lb><lb>I wanted to share...    autos   \n",
       "19997  So I picked up a 2002 4Runner recently and the...    autos   \n",
       "19998  Ok so I've posted to r/Jeep and figured I shou...    autos   \n",
       "19999  I read a lot Forums and people recommend getti...    autos   \n",
       "\n",
       "           subcategory  \n",
       "0      harley davidson  \n",
       "1      harley davidson  \n",
       "2      harley davidson  \n",
       "3      harley davidson  \n",
       "4      harley davidson  \n",
       "...                ...  \n",
       "19995           toyota  \n",
       "19996           toyota  \n",
       "19997           toyota  \n",
       "19998           toyota  \n",
       "19999           toyota  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.category == \"autos\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd691463",
   "metadata": {},
   "source": [
    "### 1.2 Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c2ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(os.path.join(data_path, \"reddit-selfposts/reddit_dataframe.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94bb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"reddit-selfposts.db\"\n",
    "con = sqlite3.connect(os.path.join(data_path, \"reddit-selfposts\", db_name))\n",
    "df.to_sql(\"posts\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64fa93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(os.path.join(data_path, \"reddit-selfposts\", db_name))\n",
    "pd.read_sql(\"SELECT * FROM posts\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4717b18",
   "metadata": {},
   "source": [
    "## 2. Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f56e4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Funny story. I went to college in Las Vegas. T...\n",
       "1        I have a stock 2010 FXD that has a rate I can'...\n",
       "2        So I'm on a bike trip with my father and we st...\n",
       "3        So I’m gonna change out my T bars that came on...\n",
       "4        A few weeks ago, somebody was looking for some...\n",
       "                               ...                        \n",
       "19995    Just picked up my first 4Runner this week! Lov...\n",
       "19996    Hello fellow runners-<lb><lb>I wanted to share...\n",
       "19997    So I picked up a 2002 4Runner recently and the...\n",
       "19998    Ok so I've posted to r/Jeep and figured I shou...\n",
       "19999    I read a lot Forums and people recommend getti...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed604690",
   "metadata": {},
   "source": [
    "### 2.1 Blueprint: Identify noise with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42ad113",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_SUSPICIOUS = re.compile(r'[&#<>{}\\[\\]\\\\]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b6db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity(text, min_len=10):\n",
    "    \"\"\"\n",
    "    returns the sahre of suspicious characters in a text\n",
    "    \"\"\"\n",
    "    if text == None or len(text) < min_len:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(RE_SUSPICIOUS.findall(text))/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ec551be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['impurity'] = df['text'].apply(impurity, min_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abcafc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>Looking at buying a 335i with 39k miles and 11...</td>\n",
       "      <td>0.214716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8630</th>\n",
       "      <td>I'm looking to lease an a4 premium plus automa...</td>\n",
       "      <td>0.165099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15141</th>\n",
       "      <td>Breakdown below:&lt;lb&gt;&lt;lb&gt;Elantra GT&lt;lb&gt;&lt;lb&gt;2.0L...</td>\n",
       "      <td>0.139130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  impurity\n",
       "14983  Looking at buying a 335i with 39k miles and 11...  0.214716\n",
       "8630   I'm looking to lease an a4 premium plus automa...  0.165099\n",
       "15141  Breakdown below:<lb><lb>Elantra GT<lb><lb>2.0L...  0.139130"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"text\", \"impurity\"]].sort_values(by=\"impurity\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6be3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;lb&gt;</th>\n",
       "      <td>100729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;tab&gt;</th>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq\n",
       "token        \n",
       "<lb>   100729\n",
       "<tab>     642"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(df, column='text', preprocess=lambda t: re.findall(r'<[\\w/]*>', t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaeaf9d",
   "metadata": {},
   "source": [
    "### 2.2 Blueprint: Removing noise with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "498d18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r\"<[^<>]*>\", \" \", text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r\"\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)\", r\"\\1\", text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r\"\\[[^\\[\\]]*\\]\", \" \", text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r\"(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)\", \" \", text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "061cd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0b23f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"impurity\"] = df.clean_text.apply(impurity, min_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a37c291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15361</th>\n",
       "      <td>Split b/w 2 genesis options. Hyundai Genesis\\ ...</td>\n",
       "      <td>0.039867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>Mustang 2018, 2019, or 2020? Must Haves!! 1. H...</td>\n",
       "      <td>0.031980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17941</th>\n",
       "      <td>Just like the title says, when I am manually s...</td>\n",
       "      <td>0.028914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16959</th>\n",
       "      <td>At the dealership, they offered an option for ...</td>\n",
       "      <td>0.026455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>I am looking at four Caymans, all are in a sim...</td>\n",
       "      <td>0.024631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>Im lookin to get a 2008 honda fit with 150000k...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>My car when I'm driving and know I'm going to ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>Hey /r/Honda, Ever since upgrading to iOS 11 a...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>I just bought a 97 civic with 105k miles on it...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>I read a lot Forums and people recommend getti...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  impurity\n",
       "15361  Split b/w 2 genesis options. Hyundai Genesis\\ ...  0.039867\n",
       "1714   Mustang 2018, 2019, or 2020? Must Haves!! 1. H...  0.031980\n",
       "17941  Just like the title says, when I am manually s...  0.028914\n",
       "16959  At the dealership, they offered an option for ...  0.026455\n",
       "12828  I am looking at four Caymans, all are in a sim...  0.024631\n",
       "...                                                  ...       ...\n",
       "6866   Im lookin to get a 2008 honda fit with 150000k...  0.000000\n",
       "6865   My car when I'm driving and know I'm going to ...  0.000000\n",
       "6864   Hey /r/Honda, Ever since upgrading to iOS 11 a...  0.000000\n",
       "6863   I just bought a 97 civic with 105k miles on it...  0.000000\n",
       "19999  I read a lot Forums and people recommend getti...  0.000000\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"clean_text\", \"impurity\"]].sort_values(by=\"impurity\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fffa48",
   "metadata": {},
   "source": [
    "### 2.3 Blueprint: Character normalization with textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6543aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The café “Saint-Raphaël” is loca-\\nted on Côte dʼAzur.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70c81b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = tprep.normalize.hyphenated_words(text)\n",
    "    text = tprep.normalize.quotation_marks(text)\n",
    "    text = tprep.normalize.unicode(text)\n",
    "    text = tprep.remove.accents(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d25c9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The café “Saint-Raphaël” is loca-\n",
      "ted on Côte dʼAzur.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b95c476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafe \"Saint-Raphael\" is located on Cote d'Azur.\n"
     ]
    }
   ],
   "source": [
    "print(normalize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a835a7",
   "metadata": {},
   "source": [
    "### 2.4 Blueprint: Pattern-based data masking with textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25592c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>2448392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>1137060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>925384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>777509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>758592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>͡</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>😔</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>³</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>℃</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq\n",
       "token         \n",
       "       2448392\n",
       "e      1137060\n",
       "t       925384\n",
       "a       777509\n",
       "o       758592\n",
       "...        ...\n",
       "͡            2\n",
       "à            2\n",
       "😔            2\n",
       "³            2\n",
       "℃            2\n",
       "\n",
       "[156 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(df, column=\"clean_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "238e10cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>www.getlowered.com</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://gm-volt.com</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://imgur.com/a/lnFec</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://imgur.com/gallery/rkdv4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.reddit.com/r/Jeep/comments/4ux232/just_ordered_an_android_head_unit_joying_jeep/</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://imgur.com/3hd0dy9</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://ir.tesla.com</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://imgur.com/a/mbS08</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.ecolamautomotive.com/#!2/kv7fq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://imgur.com/a/MXnni)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://imgur.com/gallery/XkRsw</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://imgur.com/a/tIVhr</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.youtube.com/watch?v=DuTI_jlA8v8</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://imgur.com/m0Qbj1M</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://imgur.com/JO7qBPo</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kbb.com/ford/mustang/2008/deluxe-coupe-2d/?vehicleid=197133&amp;intent=buy-used&amp;options=6279827%7ctrue&amp;category=coupe&amp;mileage=90000&amp;pricetype=retail&amp;condition=good)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://rochester.craigslist.org/cto/d/hyundai-genesis-coupe-track/6200414183.html</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    freq\n",
       "token                                                   \n",
       "www.getlowered.com                                     3\n",
       "http://gm-volt.com                                     2\n",
       "https://imgur.com/a/lnFec                              2\n",
       "https://imgur.com/gallery/rkdv4                        2\n",
       "https://www.reddit.com/r/Jeep/comments/4ux232/j...     2\n",
       "http://imgur.com/3hd0dy9                               2\n",
       "http://ir.tesla.com                                    2\n",
       "https://imgur.com/a/mbS08                              2\n",
       "http://www.ecolamautomotive.com/#!2/kv7fq              2\n",
       "https://imgur.com/a/MXnni)                             2\n",
       "http://imgur.com/gallery/XkRsw                         2\n",
       "http://imgur.com/a/tIVhr                               2\n",
       "https://www.youtube.com/watch?v=DuTI_jlA8v8            2\n",
       "http://imgur.com/m0Qbj1M                               2\n",
       "http://imgur.com/JO7qBPo                               2\n",
       "https://www.kbb.com/ford/mustang/2008/deluxe-co...     2\n",
       "https://rochester.craigslist.org/cto/d/hyundai-...     2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(df, column=\"clean_text\", preprocess=RE_URL.findall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0135c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out _URL_\n"
     ]
    }
   ],
   "source": [
    "text = \"Check out https://spacy.io/usage/spacy-101\"\n",
    "print(tprep.replace.urls(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d656c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df.clean_text.map(tprep.replace.urls)\n",
    "df[\"clean_text\"] = df.clean_text.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68c5fde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Funny story. I went to college in Las Vegas. T...\n",
       "1        I have a stock 2010 FXD that has a rate I can'...\n",
       "2        So I'm on a bike trip with my father and we st...\n",
       "3        So I'm gonna change out my T bars that came on...\n",
       "4        A few weeks ago, somebody was looking for some...\n",
       "                               ...                        \n",
       "19995    Just picked up my first 4Runner this week! Lov...\n",
       "19996    Hello fellow runners- I wanted to share my rec...\n",
       "19997    So I picked up a 2002 4Runner recently and the...\n",
       "19998    Ok so I've posted to r/Jeep and figured I shou...\n",
       "19999    I read a lot Forums and people recommend getti...\n",
       "Name: clean_text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45f9d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"text\": \"raw_text\", \"clean_text\": \"text\"}, inplace=True)\n",
    "df.drop(columns=[\"impurity\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71b953a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(os.path.join(data_path, \"reddit-selfposts\", db_name))\n",
    "df.to_sql(\"posts_cleaned\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13ec11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(os.path.join(data_path, \"reddit-selfposts\", db_name))\n",
    "pd.read_sql(\"SELECT * FROM posts_cleaned\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357b21a",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "132edd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "2019-08-10 23:32: @pete/@louis - I don't have a well-designed \n",
    "solution for today's problem. The code of module AC68 should be -1. \n",
    "Have to think a bit... #goodnight ;-) 😩😬\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef41dc9",
   "metadata": {},
   "source": [
    "### 3.1 Blueprint: Tokenization with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b68a648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019|08|10|23|32|pete|louis|don|have|well|designed|solution|for|today|problem|The|code|of|module|AC68|should|be|Have|to|think|bit|goodnight\n"
     ]
    }
   ],
   "source": [
    "tokens = re.findall(r\"\\w\\w+\", text)\n",
    "print(*tokens, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "643db3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10|23:32|@pete|@louis|I|don't|have|a|well-designed|solution|for|today's|problem|The|code|of|module|AC68|should|be|-1|Have|to|think|a|bit|#goodnight|;-)|😩|😬\n"
     ]
    }
   ],
   "source": [
    "RE_TOKEN = re.compile(r\"\"\"\n",
    "               ( [#]?[@\\w'’\\.\\-\\:]*\\w     # words, hash tags and email adresses\n",
    "               | [:;<]\\-?[\\)\\(3]          # coarse pattern for basic text emojis\n",
    "               | [\\U0001F100-\\U0001FFFF]  # coarse code range for unicode emojis\n",
    "               )\n",
    "               \"\"\", re.VERBOSE)\n",
    "\n",
    "def tokenize(text):\n",
    "    return RE_TOKEN.findall(text)\n",
    "\n",
    "tokens = tokenize(text)\n",
    "print(*tokens, sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba72064",
   "metadata": {},
   "source": [
    "### 3.2 Tokenization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "395e631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-10|23:32|:|@|pete/|@|louis|-|I|do|n't|have|a|well-designed|solution|for|today|'s|problem|.|The|code|of|module|AC68|should|be|-1|.|Have|to|think|a|bit|...|#|goodnight|;|-|)|😩😬\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "print(*tokens, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bf6eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nicolas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30f26beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-|10|23:32|:|@pete|/|@louis|-|I|don't|have|a|well-designed|solution|for|today's|problem|.|The|code|of|module|AC68|should|be|-|1|.|Have|to|think|a|bit|...|#goodnight|;-)|😩|😬\n"
     ]
    }
   ],
   "source": [
    "# Not in book: Tweet Tokenizer\n",
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(*tokens, sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bdd54c",
   "metadata": {},
   "source": [
    "## 4. Linguistic processing with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e827422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-08 20:37:58.694715: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:58.694740: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-08 20:37:59.810297: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-08 20:37:59.810345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-08 20:37:59.810453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-08 20:37:59.810861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:26:00.0 name: NVIDIA GeForce GTX 1660 Ti computeCapability: 7.5\n",
      "coreClock: 1.875GHz coreCount: 24 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 268.26GiB/s\n",
      "2023-01-08 20:37:59.810940: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:59.810987: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:59.811031: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:59.811060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-08 20:37:59.811081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-08 20:37:59.811102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-08 20:37:59.811142: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:59.811186: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-08 20:37:59.811196: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.27.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.62.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: setuptools in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (65.6.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.22.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: jinja2 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nicolas/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "806f4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "617d6f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f14db8bcd60>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f14db89d820>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f14dc41ca50>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f15d9249fc0>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f15d9249b40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f14dc41c9e0>)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c844f285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f15cde25580>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f15cdca6be0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f15cdc27180>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f15cdc2f080>)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df6797",
   "metadata": {},
   "source": [
    "### 4.1 Processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d634560",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "819e7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83d59f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My best friend Ryan Peters likes fancy adventure games."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6cbdfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fb86ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My|best|friend|Ryan|Peters|likes|fancy|adventure|games|.|"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9011603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My best friend Ryan Peters likes fancy adventure games."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84652d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My best friend Ryan Peters likes fancy adventure games.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "512a88b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True PRON\n",
      "False ADJ\n",
      "False NOUN\n",
      "False PROPN\n",
      "False PROPN\n",
      "False VERB\n",
      "False ADJ\n",
      "False NOUN\n",
      "False NOUN\n",
      "False PUNCT\n"
     ]
    }
   ],
   "source": [
    "for t in doc:\n",
    "    print(t.is_stop, t.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4963342",
   "metadata": {},
   "source": [
    "### 4.2 Customizing tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d88912c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"@Pete: choose low-carb #food #eat-smart. _url_ ;-) 😋👍\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5178c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73efc926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low|-|carb|#|food|#|eat|-|smart|.|_|url|_|;-)|😋|👍|"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0892b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nuthin\n",
      "ü.\n",
      "p.m\n",
      "Kan\n",
      "Mar\n",
      "When's\n",
      " \n",
      "Sept.\n",
      "c.\n",
      "Mont.\n",
      ":-}\n",
      "12a.m.\n",
      "e.g\n",
      "Why's\n",
      "😋\n",
      "it\n",
      "6p.m\n",
      "Jr.\n",
      "Who’s\n",
      "K.\n",
      "Calif.\n",
      "e\n",
      "Ill.\n",
      "O'clock\n",
      "o'clock\n",
      "Mich.\n",
      "is\n",
      ":-o\n",
      "n.\n",
      "Might\n",
      "Nov\n",
      ">.<\n",
      "he's\n",
      "it’s\n",
      "where’s\n",
      "low\n",
      "Wash.\n",
      "where\n",
      ":-*\n",
      "she's\n",
      "g.\n",
      ":()\n",
      ")-:\n",
      "X\n",
      "S.C.\n",
      "Del\n",
      "Why’s\n",
      "0.o\n",
      "must\n",
      "Goin'\n",
      "4a.m.\n",
      "5p.m.\n",
      "Mass.\n",
      "co.\n",
      "━\n",
      "(-_-)\n",
      "Ariz\n",
      "had\n",
      "0\n",
      "vs.\n",
      "x.\n",
      "><(((*>\n",
      "11a.m.\n",
      "-o\n",
      "When’s\n",
      "Calif\n",
      "does\n",
      "nothin’\n",
      "’S\n",
      "Cos\n",
      "I.e\n",
      "8-)\n",
      "Would\n",
      "do\n",
      "\"\n",
      "Rev.\n",
      "’s\n",
      "N.M.\n",
      "°c.\n",
      "b\n",
      "O.o\n",
      "might\n",
      "q.\n",
      "adventure\n",
      "this's\n",
      "’’\n",
      "Goin’\n",
      "likes\n",
      "Has\n",
      "N.J.\n",
      "pm\n",
      "ought\n",
      "Dec\n",
      "food\n",
      "3p.m\n",
      "<space>\n",
      "Ore.\n",
      "10p.m\n",
      "h.\n",
      "where's\n",
      "doin’\n",
      "What's\n",
      "he’s\n",
      "'cos\n",
      "ä\n",
      "That's\n",
      "11a.m\n",
      "these\n",
      "1p.m\n",
      "Tenn\n",
      ";D\n",
      "Miss\n",
      "Ga\n",
      "Must\n",
      "9p.m\n",
      "somethin\n",
      "Nev.\n",
      "What\n",
      "z.\n",
      "’\n",
      "there's\n",
      "'Cause\n",
      "ü\n",
      "r\n",
      "9\n",
      "Dec.\n",
      "︵\n",
      "v.s\n",
      "Jun.\n",
      ":-))\n",
      ";_;\n",
      "When\n",
      "D.C.\n",
      "Have\n",
      "You\n",
      "10\n",
      "Where's\n",
      "6a.m\n",
      "o_o\n",
      "O\n",
      "'coz\n",
      "'cause\n",
      "co\n",
      "doin\n",
      "how's\n",
      "i.e\n",
      "._.\n",
      "c’m\n",
      "Prof.\n",
      ":’-)\n",
      "havin'\n",
      "Co.\n",
      "Va.\n",
      "Mt\n",
      "|\n",
      ":((\n",
      "O’clock\n",
      "Let\n",
      "Del.\n",
      "xDD\n",
      "Prof\n",
      "i.e.\n",
      "Ai\n",
      "lovin'\n",
      "when’s\n",
      "Does\n",
      "Minn\n",
      "g\n",
      "👍\n",
      "12a.m\n",
      "Who's\n",
      "-\n",
      "(\n",
      "La\n",
      "11\n",
      "(;\n",
      "12p.m.\n",
      "Mich\n",
      "n’t\n",
      "_\n",
      "Not\n",
      "choose\n",
      "1p.m.\n",
      "Okla.\n",
      "Okla\n",
      "what's\n",
      "□\n",
      ":P\n",
      "w\n",
      "cos\n",
      ":'-(\n",
      "Ph.D.\n",
      "It’s\n",
      "Va\n",
      "Nothin’\n",
      "Ltd.\n",
      "would\n",
      ":-/\n",
      "Rep\n",
      "Was\n",
      ";\n",
      "a.\n",
      ":)))\n",
      "k\n",
      "o.\n",
      "XD\n",
      "#\n",
      "Ga.\n",
      "Sha\n",
      "C\n",
      "Ought\n",
      "Sep\n",
      ">:o\n",
      ":-)\n",
      "<3\n",
      "d\n",
      "8)\n",
      "Who\n",
      "(¬_¬)\n",
      "Pa.\n",
      "f\n",
      "V_V\n",
      ":(((\n",
      "need\n",
      "That’s\n",
      "]\n",
      "-8\n",
      "c\n",
      "(^_^)\n",
      "@Pete\n",
      "v.s.\n",
      ":D\n",
      "m\n",
      "cause\n",
      "m.\n",
      "C'm\n",
      "8-\n",
      "0_0\n",
      "Somethin’\n",
      "¬_¬\n",
      "you\n",
      "=\n",
      "that’s\n",
      "was\n",
      "’m\n",
      "How’s\n",
      "F\n",
      "what’s\n",
      "‘s\n",
      "y\n",
      ":o\n",
      "Jr\n",
      "Mont\n",
      ":|\n",
      "Where\n",
      ":1\n",
      "nt\n",
      "this’s\n",
      "0.0\n",
      "11p.m\n",
      "Gen\n",
      "why’s\n",
      "Oct.\n",
      "Let's\n",
      "=D\n",
      "My\n",
      "-0\n",
      ".\n",
      "who\n",
      "Gov.\n",
      "May\n",
      "Nov.\n",
      ":o)\n",
      "Mr.\n",
      "’cos\n",
      "'ve\n",
      "Ky.\n",
      "why\n",
      "Are\n",
      "\\\n",
      "how\n",
      "9a.m\n",
      "could\n",
      "5p.m\n",
      "ಠ_ಠ\n",
      "'S\n",
      "Havin’\n",
      "8a.m\n",
      "┻\n",
      "h\n",
      "0_o\n",
      "'m\n",
      "Nuthin'\n",
      "[=\n",
      "ä.\n",
      "2p.m\n",
      "ö.\n",
      "ca\n",
      "'Coz\n",
      "o’clock\n",
      ":p\n",
      "doin'\n",
      "cuz\n",
      ":-(\n",
      ":-((\n",
      "<\n",
      "ol’\n",
      "Nebr.\n",
      "c'm\n",
      "Cuz\n",
      "o.o\n",
      "Havin\n",
      "a.m\n",
      "those\n",
      "space\n",
      "He\n",
      "Neb\n",
      "Ms.\n",
      "Nev\n",
      "9p.m.\n",
      "n't\n",
      "Ol’\n",
      "¯\\(ツ)/¯\n",
      "were\n",
      "t\n",
      "ta\n",
      "nothin'\n",
      "=)\n",
      "a\n",
      "somethin’\n",
      "dare\n",
      "’cause\n",
      "Lovin’\n",
      "’re\n",
      "goin’\n",
      "'Cos\n",
      "Messrs\n",
      "5\n",
      "/3\n",
      "ll\n",
      "this\n",
      "'y\n",
      "*\n",
      "12p.m\n",
      ":x\n",
      "Jan.\n",
      "Sep.\n",
      "Were\n",
      "Jan\n",
      "]=\n",
      "who's\n",
      "Jul.\n",
      "/\n",
      "2a.m.\n",
      "Doin’\n",
      ":(\n",
      "8D\n",
      "j.\n",
      "°k.\n",
      ":-)))\n",
      "nuthin’\n",
      "O_o\n",
      "O_O\n",
      "nuff\n",
      "(-:\n",
      ":\n",
      "they\n",
      "=/\n",
      "He’s\n",
      "^_^\n",
      "We\n",
      "[-:\n",
      "eat\n",
      "(:\n",
      "’Coz\n",
      "he\n",
      ":-p\n",
      "He's\n",
      "games\n",
      "Let’s\n",
      "Can\n",
      "=[\n",
      "'nuff\n",
      "It's\n",
      "Jun\n",
      "'\n",
      "Lovin'\n",
      "l\n",
      "Lovin\n",
      "when's\n",
      "u\n",
      "Ol\n",
      "Dare\n",
      ":-O\n",
      "q\n",
      ";-)\n",
      "there\n",
      "’nuff\n",
      "havin\n",
      "'bout\n",
      "’Cause\n",
      "Need\n",
      "Somethin\n",
      "gon\n",
      "333\n",
      "N.C.\n",
      "\\n\n",
      "E.G.\n",
      "Ia\n",
      "F.\n",
      "b.\n",
      "v\n",
      "got\n",
      "What’s\n",
      "=3\n",
      ">.>\n",
      ":}\n",
      "Wash\n",
      "3a.m\n",
      "Conn\n",
      "w/o\n",
      "Mass\n",
      "Colo\n",
      ":))\n",
      "1a.m.\n",
      "2p.m.\n",
      "11p.m.\n",
      "It\n",
      "j\n",
      "Those\n",
      "bout\n",
      "Ark.\n",
      "who’s\n",
      "that's\n",
      "Ma’am\n",
      "\\\")\n",
      "’coz\n",
      "</3\n",
      "7a.m.\n",
      "Id.\n",
      "St.\n",
      "Mr\n",
      "=|\n",
      "^___^\n",
      "v_v\n",
      ":’-(\n",
      "Bros\n",
      "(>_<)\n",
      "7a.m\n",
      "Mo\n",
      "D.\n",
      ":'(\n",
      "Ma'am\n",
      "Havin'\n",
      "-O\n",
      "Why\n",
      "(=\n",
      "k.\n",
      "K\n",
      "she’s\n",
      "a.m.\n",
      "Wo\n",
      ":-3\n",
      "Apr.\n",
      "Miss.\n",
      "or\n",
      "when\n",
      "o_0\n",
      "Adm.\n",
      "it's\n",
      "Dr\n",
      "Gen.\n",
      "Is\n",
      "lovin’\n",
      "she\n",
      " \n",
      "Feb.\n",
      "Fla.\n",
      "Id\n",
      "-__-\n",
      "Apr\n",
      "Messrs.\n",
      "ol'\n",
      "<333\n",
      "(-;\n",
      "1a.m\n",
      "may\n",
      "(o:\n",
      "=]\n",
      "C’m\n",
      "all\n",
      "Ltd\n",
      "Doin\n",
      "v.v\n",
      "Fla\n",
      "what\n",
      "Kan.\n",
      "-P\n",
      "Minn.\n",
      "p.m.\n",
      "7\n",
      "and/or\n",
      "Ind\n",
      "Sept\n",
      "‘S\n",
      ":X\n",
      "'s\n",
      "6a.m.\n",
      "N.H.\n",
      "''\n",
      "Sen\n",
      "coz\n",
      "i.\n",
      "nothin\n",
      "Bros.\n",
      "8-D\n",
      ":-D\n",
      "[\n",
      "9a.m.\n",
      "Ark\n",
      "This’s\n",
      "’Cuz\n",
      "8p.m\n",
      "Co\n",
      "10a.m.\n",
      "-x\n",
      "This\n",
      "Rev\n",
      "Ms\n",
      "re\n",
      "Gon\n",
      "3a.m.\n",
      "There\n",
      "\\t\n",
      "D\n",
      "Ala.\n",
      "12\n",
      "lovin\n",
      "1\n",
      "S\n",
      "There's\n",
      "4p.m\n",
      "Mrs\n",
      "Ol'\n",
      "(._.)\n",
      "friend\n",
      "Gov\n",
      ":-0\n",
      "Feb\n",
      "N.Y.\n",
      "-p\n",
      "Nuthin\n",
      "nuthin'\n",
      "ma’am\n",
      "):\n",
      "N.D.\n",
      "Corp\n",
      ")\n",
      "These\n",
      "6p.m.\n",
      "ma'am\n",
      "why's\n",
      "-|\n",
      "fancy\n",
      "Ky\n",
      "url\n",
      "C++\n",
      "somethin'\n",
      "e.g.\n",
      "-D\n",
      "not\n",
      "Could\n",
      "That\n",
      "Tenn.\n",
      "did\n",
      "(-8\n",
      "w.\n",
      "smart\n",
      "’Cos\n",
      "I\n",
      "f.\n",
      ":]\n",
      "I.e.\n",
      "°K.\n",
      "’d\n",
      "-3\n",
      "e.\n",
      "Do\n",
      "V.V\n",
      "Wis\n",
      "Ariz.\n",
      "has\n",
      "Where’s\n",
      "‘\n",
      "’cuz\n",
      "Inc\n",
      "Peters\n",
      "2a.m\n",
      "Md.\n",
      "There’s\n",
      "Ala\n",
      "Ind.\n",
      "°F.\n",
      "Rep.\n",
      ":')\n",
      ";-D\n",
      "have\n",
      "°f.\n",
      "Doin'\n",
      ":>\n",
      "Conn.\n",
      ">\n",
      "She\n",
      "sha\n",
      "y’\n",
      "d.\n",
      "5a.m\n",
      ":O\n",
      "o.O\n",
      "vs\n",
      "╯\n",
      "Did\n",
      ":0\n",
      "7p.m\n",
      "s\n",
      "Nothin'\n",
      "p.\n",
      "-/\n",
      "there’s\n",
      "^__^\n",
      "p\n",
      "'ll\n",
      "best\n",
      "She’s\n",
      "'re\n",
      "am\n",
      "'cuz\n",
      "Mo.\n",
      "Corp.\n",
      "Neb.\n",
      "havin’\n",
      "ol\n",
      ">:(\n",
      "<.<\n",
      "Inc.\n",
      "Pa\n",
      "3p.m.\n",
      "°\n",
      ":’(\n",
      ":’)\n",
      "can\n",
      "Jul\n",
      "8\n",
      "Ak.\n",
      "we\n",
      "<33\n",
      "Mt.\n",
      "o_O\n",
      "n\n",
      "em\n",
      "’bout\n",
      "Aug.\n",
      "}\n",
      "(*_*)\n",
      "(╯°□°）╯︵┻━┻\n",
      "on\n",
      "10a.m\n",
      "3\n",
      "Ph\n",
      "How's\n",
      ":/\n",
      "x\n",
      "’ve\n",
      "[:\n",
      "'Cuz\n",
      "Ca\n",
      "that\n",
      "o\n",
      "This's\n",
      ":'-)\n",
      "5a.m.\n",
      "\t\n",
      "y.\n",
      "St\n",
      "Should\n",
      "6\n",
      "@_@\n",
      "y'\n",
      ":3\n",
      "Mrs.\n",
      "10p.m.\n",
      "Oct\n",
      "7p.m.\n",
      "Md\n",
      "ಠ︵ಠ\n",
      "33\n",
      ";)\n",
      "Ryan\n",
      "'d\n",
      "Kans\n",
      ":-(((\n",
      "na\n",
      "i\n",
      "-X\n",
      "xD\n",
      "’ll\n",
      "t.\n",
      "°C.\n",
      "Ak\n",
      "8p.m.\n",
      "'em\n",
      "carb\n",
      "La.\n",
      ":-X\n",
      "v.\n",
      "Nothin\n",
      "Nuthin’\n",
      ":)\n",
      "z\n",
      "-_-\n",
      "(ಠ_ಠ)\n",
      "’em\n",
      "Ia.\n",
      "Sen.\n",
      ":->\n",
      "How\n",
      "4\n",
      "They\n",
      "4p.m.\n",
      "）\n",
      "how’s\n",
      "ö\n",
      "Dr.\n",
      "2\n",
      "ai\n",
      "let’s\n",
      "Had\n",
      "let's\n",
      "8a.m.\n",
      "goin'\n",
      "o.0\n",
      "r.\n",
      "Got\n",
      "Aug\n",
      "l.\n",
      "XDD\n",
      "P\n",
      "Kans.\n",
      "Cause\n",
      "s.\n",
      "wo\n",
      "Goin\n",
      "C.\n",
      ":-x\n",
      "4a.m\n",
      "u.\n",
      "should\n",
      ":-]\n",
      "E.g\n",
      "’y\n",
      "Ill\n",
      "I.E.\n",
      "=(\n",
      "Wis.\n",
      "are\n",
      "Coz\n",
      "Nebr\n",
      "Adm\n",
      "O.O\n",
      "and\n",
      "Colo.\n",
      "Somethin'\n",
      ":-P\n",
      "Ore\n",
      "—\n",
      "goin\n",
      "\n",
      "\n",
      "let\n",
      "Mar.\n",
      "She's\n",
      "ve\n",
      "E.g.\n",
      ":-|\n",
      ":*\n"
     ]
    }
   ],
   "source": [
    "for x in nlp.vocab:\n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e30853fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(nlp):\n",
    "    # use default patterns except the ones mathced by re.search\n",
    "    prefixes = [pattern for pattern in nlp.Defaults.prefixes if pattern not in [\"-\", \"_\", \"#\"]]\n",
    "    suffixes = [pattern for pattern in nlp.Defaults.suffixes if pattern not in [\"_\"]]\n",
    "    infixes = [pattern for pattern in nlp.Defaults.infixes if not re.search(pattern, \"xx-xx\")]\n",
    "    return Tokenizer(\n",
    "        vocab = nlp.vocab,\n",
    "        rules = nlp.Defaults.tokenizer_exceptions,\n",
    "        prefix_search = compile_prefix_regex(prefixes).search,\n",
    "        suffix_search = compile_suffix_regex(suffixes).search,\n",
    "        infix_finditer = compile_infix_regex(infixes).finditer,\n",
    "        token_match = nlp.Defaults.token_match\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fa7f399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['§',\n",
       " '%',\n",
       " '=',\n",
       " '—',\n",
       " '–',\n",
       " '\\\\+(?![0-9])',\n",
       " '…',\n",
       " '……',\n",
       " ',',\n",
       " ':',\n",
       " ';',\n",
       " '\\\\!',\n",
       " '\\\\?',\n",
       " '¿',\n",
       " '؟',\n",
       " '¡',\n",
       " '\\\\(',\n",
       " '\\\\)',\n",
       " '\\\\[',\n",
       " '\\\\]',\n",
       " '\\\\{',\n",
       " '\\\\}',\n",
       " '<',\n",
       " '>',\n",
       " '_',\n",
       " '#',\n",
       " '\\\\*',\n",
       " '&',\n",
       " '。',\n",
       " '？',\n",
       " '！',\n",
       " '，',\n",
       " '、',\n",
       " '；',\n",
       " '：',\n",
       " '～',\n",
       " '·',\n",
       " '।',\n",
       " '،',\n",
       " '۔',\n",
       " '؛',\n",
       " '٪',\n",
       " '\\\\.\\\\.+',\n",
       " '…',\n",
       " \"\\\\'\",\n",
       " '\"',\n",
       " '”',\n",
       " '“',\n",
       " '`',\n",
       " '‘',\n",
       " '´',\n",
       " '’',\n",
       " '‚',\n",
       " ',',\n",
       " '„',\n",
       " '»',\n",
       " '«',\n",
       " '「',\n",
       " '」',\n",
       " '『',\n",
       " '』',\n",
       " '（',\n",
       " '）',\n",
       " '〔',\n",
       " '〕',\n",
       " '【',\n",
       " '】',\n",
       " '《',\n",
       " '》',\n",
       " '〈',\n",
       " '〉',\n",
       " '\\\\$',\n",
       " '£',\n",
       " '€',\n",
       " '¥',\n",
       " '฿',\n",
       " 'US\\\\$',\n",
       " 'C\\\\$',\n",
       " 'A\\\\$',\n",
       " '₽',\n",
       " '﷼',\n",
       " '₴',\n",
       " '₠',\n",
       " '₡',\n",
       " '₢',\n",
       " '₣',\n",
       " '₤',\n",
       " '₥',\n",
       " '₦',\n",
       " '₧',\n",
       " '₨',\n",
       " '₩',\n",
       " '₪',\n",
       " '₫',\n",
       " '€',\n",
       " '₭',\n",
       " '₮',\n",
       " '₯',\n",
       " '₰',\n",
       " '₱',\n",
       " '₲',\n",
       " '₳',\n",
       " '₴',\n",
       " '₵',\n",
       " '₶',\n",
       " '₷',\n",
       " '₸',\n",
       " '₹',\n",
       " '₺',\n",
       " '₻',\n",
       " '₼',\n",
       " '₽',\n",
       " '₾',\n",
       " '₿',\n",
       " '[\\\\u00A6\\\\u00A9\\\\u00AE\\\\u00B0\\\\u0482\\\\u058D\\\\u058E\\\\u060E\\\\u060F\\\\u06DE\\\\u06E9\\\\u06FD\\\\u06FE\\\\u07F6\\\\u09FA\\\\u0B70\\\\u0BF3-\\\\u0BF8\\\\u0BFA\\\\u0C7F\\\\u0D4F\\\\u0D79\\\\u0F01-\\\\u0F03\\\\u0F13\\\\u0F15-\\\\u0F17\\\\u0F1A-\\\\u0F1F\\\\u0F34\\\\u0F36\\\\u0F38\\\\u0FBE-\\\\u0FC5\\\\u0FC7-\\\\u0FCC\\\\u0FCE\\\\u0FCF\\\\u0FD5-\\\\u0FD8\\\\u109E\\\\u109F\\\\u1390-\\\\u1399\\\\u1940\\\\u19DE-\\\\u19FF\\\\u1B61-\\\\u1B6A\\\\u1B74-\\\\u1B7C\\\\u2100\\\\u2101\\\\u2103-\\\\u2106\\\\u2108\\\\u2109\\\\u2114\\\\u2116\\\\u2117\\\\u211E-\\\\u2123\\\\u2125\\\\u2127\\\\u2129\\\\u212E\\\\u213A\\\\u213B\\\\u214A\\\\u214C\\\\u214D\\\\u214F\\\\u218A\\\\u218B\\\\u2195-\\\\u2199\\\\u219C-\\\\u219F\\\\u21A1\\\\u21A2\\\\u21A4\\\\u21A5\\\\u21A7-\\\\u21AD\\\\u21AF-\\\\u21CD\\\\u21D0\\\\u21D1\\\\u21D3\\\\u21D5-\\\\u21F3\\\\u2300-\\\\u2307\\\\u230C-\\\\u231F\\\\u2322-\\\\u2328\\\\u232B-\\\\u237B\\\\u237D-\\\\u239A\\\\u23B4-\\\\u23DB\\\\u23E2-\\\\u2426\\\\u2440-\\\\u244A\\\\u249C-\\\\u24E9\\\\u2500-\\\\u25B6\\\\u25B8-\\\\u25C0\\\\u25C2-\\\\u25F7\\\\u2600-\\\\u266E\\\\u2670-\\\\u2767\\\\u2794-\\\\u27BF\\\\u2800-\\\\u28FF\\\\u2B00-\\\\u2B2F\\\\u2B45\\\\u2B46\\\\u2B4D-\\\\u2B73\\\\u2B76-\\\\u2B95\\\\u2B98-\\\\u2BC8\\\\u2BCA-\\\\u2BFE\\\\u2CE5-\\\\u2CEA\\\\u2E80-\\\\u2E99\\\\u2E9B-\\\\u2EF3\\\\u2F00-\\\\u2FD5\\\\u2FF0-\\\\u2FFB\\\\u3004\\\\u3012\\\\u3013\\\\u3020\\\\u3036\\\\u3037\\\\u303E\\\\u303F\\\\u3190\\\\u3191\\\\u3196-\\\\u319F\\\\u31C0-\\\\u31E3\\\\u3200-\\\\u321E\\\\u322A-\\\\u3247\\\\u3250\\\\u3260-\\\\u327F\\\\u328A-\\\\u32B0\\\\u32C0-\\\\u32FE\\\\u3300-\\\\u33FF\\\\u4DC0-\\\\u4DFF\\\\uA490-\\\\uA4C6\\\\uA828-\\\\uA82B\\\\uA836\\\\uA837\\\\uA839\\\\uAA77-\\\\uAA79\\\\uFDFD\\\\uFFE4\\\\uFFE8\\\\uFFED\\\\uFFEE\\\\uFFFC\\\\uFFFD\\\\U00010137-\\\\U0001013F\\\\U00010179-\\\\U00010189\\\\U0001018C-\\\\U0001018E\\\\U00010190-\\\\U0001019B\\\\U000101A0\\\\U000101D0-\\\\U000101FC\\\\U00010877\\\\U00010878\\\\U00010AC8\\\\U0001173F\\\\U00016B3C-\\\\U00016B3F\\\\U00016B45\\\\U0001BC9C\\\\U0001D000-\\\\U0001D0F5\\\\U0001D100-\\\\U0001D126\\\\U0001D129-\\\\U0001D164\\\\U0001D16A-\\\\U0001D16C\\\\U0001D183\\\\U0001D184\\\\U0001D18C-\\\\U0001D1A9\\\\U0001D1AE-\\\\U0001D1E8\\\\U0001D200-\\\\U0001D241\\\\U0001D245\\\\U0001D300-\\\\U0001D356\\\\U0001D800-\\\\U0001D9FF\\\\U0001DA37-\\\\U0001DA3A\\\\U0001DA6D-\\\\U0001DA74\\\\U0001DA76-\\\\U0001DA83\\\\U0001DA85\\\\U0001DA86\\\\U0001ECAC\\\\U0001F000-\\\\U0001F02B\\\\U0001F030-\\\\U0001F093\\\\U0001F0A0-\\\\U0001F0AE\\\\U0001F0B1-\\\\U0001F0BF\\\\U0001F0C1-\\\\U0001F0CF\\\\U0001F0D1-\\\\U0001F0F5\\\\U0001F110-\\\\U0001F16B\\\\U0001F170-\\\\U0001F1AC\\\\U0001F1E6-\\\\U0001F202\\\\U0001F210-\\\\U0001F23B\\\\U0001F240-\\\\U0001F248\\\\U0001F250\\\\U0001F251\\\\U0001F260-\\\\U0001F265\\\\U0001F300-\\\\U0001F3FA\\\\U0001F400-\\\\U0001F6D4\\\\U0001F6E0-\\\\U0001F6EC\\\\U0001F6F0-\\\\U0001F6F9\\\\U0001F700-\\\\U0001F773\\\\U0001F780-\\\\U0001F7D8\\\\U0001F800-\\\\U0001F80B\\\\U0001F810-\\\\U0001F847\\\\U0001F850-\\\\U0001F859\\\\U0001F860-\\\\U0001F887\\\\U0001F890-\\\\U0001F8AD\\\\U0001F900-\\\\U0001F90B\\\\U0001F910-\\\\U0001F93E\\\\U0001F940-\\\\U0001F970\\\\U0001F973-\\\\U0001F976\\\\U0001F97A\\\\U0001F97C-\\\\U0001F9A2\\\\U0001F9B0-\\\\U0001F9B9\\\\U0001F9C0-\\\\U0001F9C2\\\\U0001F9D0-\\\\U0001F9FF\\\\U0001FA60-\\\\U0001FA6D]']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a49bc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\.\\\\.+',\n",
       " '…',\n",
       " '[\\\\u00A6\\\\u00A9\\\\u00AE\\\\u00B0\\\\u0482\\\\u058D\\\\u058E\\\\u060E\\\\u060F\\\\u06DE\\\\u06E9\\\\u06FD\\\\u06FE\\\\u07F6\\\\u09FA\\\\u0B70\\\\u0BF3-\\\\u0BF8\\\\u0BFA\\\\u0C7F\\\\u0D4F\\\\u0D79\\\\u0F01-\\\\u0F03\\\\u0F13\\\\u0F15-\\\\u0F17\\\\u0F1A-\\\\u0F1F\\\\u0F34\\\\u0F36\\\\u0F38\\\\u0FBE-\\\\u0FC5\\\\u0FC7-\\\\u0FCC\\\\u0FCE\\\\u0FCF\\\\u0FD5-\\\\u0FD8\\\\u109E\\\\u109F\\\\u1390-\\\\u1399\\\\u1940\\\\u19DE-\\\\u19FF\\\\u1B61-\\\\u1B6A\\\\u1B74-\\\\u1B7C\\\\u2100\\\\u2101\\\\u2103-\\\\u2106\\\\u2108\\\\u2109\\\\u2114\\\\u2116\\\\u2117\\\\u211E-\\\\u2123\\\\u2125\\\\u2127\\\\u2129\\\\u212E\\\\u213A\\\\u213B\\\\u214A\\\\u214C\\\\u214D\\\\u214F\\\\u218A\\\\u218B\\\\u2195-\\\\u2199\\\\u219C-\\\\u219F\\\\u21A1\\\\u21A2\\\\u21A4\\\\u21A5\\\\u21A7-\\\\u21AD\\\\u21AF-\\\\u21CD\\\\u21D0\\\\u21D1\\\\u21D3\\\\u21D5-\\\\u21F3\\\\u2300-\\\\u2307\\\\u230C-\\\\u231F\\\\u2322-\\\\u2328\\\\u232B-\\\\u237B\\\\u237D-\\\\u239A\\\\u23B4-\\\\u23DB\\\\u23E2-\\\\u2426\\\\u2440-\\\\u244A\\\\u249C-\\\\u24E9\\\\u2500-\\\\u25B6\\\\u25B8-\\\\u25C0\\\\u25C2-\\\\u25F7\\\\u2600-\\\\u266E\\\\u2670-\\\\u2767\\\\u2794-\\\\u27BF\\\\u2800-\\\\u28FF\\\\u2B00-\\\\u2B2F\\\\u2B45\\\\u2B46\\\\u2B4D-\\\\u2B73\\\\u2B76-\\\\u2B95\\\\u2B98-\\\\u2BC8\\\\u2BCA-\\\\u2BFE\\\\u2CE5-\\\\u2CEA\\\\u2E80-\\\\u2E99\\\\u2E9B-\\\\u2EF3\\\\u2F00-\\\\u2FD5\\\\u2FF0-\\\\u2FFB\\\\u3004\\\\u3012\\\\u3013\\\\u3020\\\\u3036\\\\u3037\\\\u303E\\\\u303F\\\\u3190\\\\u3191\\\\u3196-\\\\u319F\\\\u31C0-\\\\u31E3\\\\u3200-\\\\u321E\\\\u322A-\\\\u3247\\\\u3250\\\\u3260-\\\\u327F\\\\u328A-\\\\u32B0\\\\u32C0-\\\\u32FE\\\\u3300-\\\\u33FF\\\\u4DC0-\\\\u4DFF\\\\uA490-\\\\uA4C6\\\\uA828-\\\\uA82B\\\\uA836\\\\uA837\\\\uA839\\\\uAA77-\\\\uAA79\\\\uFDFD\\\\uFFE4\\\\uFFE8\\\\uFFED\\\\uFFEE\\\\uFFFC\\\\uFFFD\\\\U00010137-\\\\U0001013F\\\\U00010179-\\\\U00010189\\\\U0001018C-\\\\U0001018E\\\\U00010190-\\\\U0001019B\\\\U000101A0\\\\U000101D0-\\\\U000101FC\\\\U00010877\\\\U00010878\\\\U00010AC8\\\\U0001173F\\\\U00016B3C-\\\\U00016B3F\\\\U00016B45\\\\U0001BC9C\\\\U0001D000-\\\\U0001D0F5\\\\U0001D100-\\\\U0001D126\\\\U0001D129-\\\\U0001D164\\\\U0001D16A-\\\\U0001D16C\\\\U0001D183\\\\U0001D184\\\\U0001D18C-\\\\U0001D1A9\\\\U0001D1AE-\\\\U0001D1E8\\\\U0001D200-\\\\U0001D241\\\\U0001D245\\\\U0001D300-\\\\U0001D356\\\\U0001D800-\\\\U0001D9FF\\\\U0001DA37-\\\\U0001DA3A\\\\U0001DA6D-\\\\U0001DA74\\\\U0001DA76-\\\\U0001DA83\\\\U0001DA85\\\\U0001DA86\\\\U0001ECAC\\\\U0001F000-\\\\U0001F02B\\\\U0001F030-\\\\U0001F093\\\\U0001F0A0-\\\\U0001F0AE\\\\U0001F0B1-\\\\U0001F0BF\\\\U0001F0C1-\\\\U0001F0CF\\\\U0001F0D1-\\\\U0001F0F5\\\\U0001F110-\\\\U0001F16B\\\\U0001F170-\\\\U0001F1AC\\\\U0001F1E6-\\\\U0001F202\\\\U0001F210-\\\\U0001F23B\\\\U0001F240-\\\\U0001F248\\\\U0001F250\\\\U0001F251\\\\U0001F260-\\\\U0001F265\\\\U0001F300-\\\\U0001F3FA\\\\U0001F400-\\\\U0001F6D4\\\\U0001F6E0-\\\\U0001F6EC\\\\U0001F6F0-\\\\U0001F6F9\\\\U0001F700-\\\\U0001F773\\\\U0001F780-\\\\U0001F7D8\\\\U0001F800-\\\\U0001F80B\\\\U0001F810-\\\\U0001F847\\\\U0001F850-\\\\U0001F859\\\\U0001F860-\\\\U0001F887\\\\U0001F890-\\\\U0001F8AD\\\\U0001F900-\\\\U0001F90B\\\\U0001F910-\\\\U0001F93E\\\\U0001F940-\\\\U0001F970\\\\U0001F973-\\\\U0001F976\\\\U0001F97A\\\\U0001F97C-\\\\U0001F9A2\\\\U0001F9B0-\\\\U0001F9B9\\\\U0001F9C0-\\\\U0001F9C2\\\\U0001F9D0-\\\\U0001F9FF\\\\U0001FA60-\\\\U0001FA6D]',\n",
       " '(?<=[0-9])[+\\\\-\\\\*^](?=[0-9-])',\n",
       " '(?<=[a-z\\\\uFF41-\\\\uFF5A\\\\u00DF-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0101\\\\u0103\\\\u0105\\\\u0107\\\\u0109\\\\u010B\\\\u010D\\\\u010F\\\\u0111\\\\u0113\\\\u0115\\\\u0117\\\\u0119\\\\u011B\\\\u011D\\\\u011F\\\\u0121\\\\u0123\\\\u0125\\\\u0127\\\\u0129\\\\u012B\\\\u012D\\\\u012F\\\\u0131\\\\u0133\\\\u0135\\\\u0137\\\\u0138\\\\u013A\\\\u013C\\\\u013E\\\\u0140\\\\u0142\\\\u0144\\\\u0146\\\\u0148\\\\u0149\\\\u014B\\\\u014D\\\\u014F\\\\u0151\\\\u0153\\\\u0155\\\\u0157\\\\u0159\\\\u015B\\\\u015D\\\\u015F\\\\u0161\\\\u0163\\\\u0165\\\\u0167\\\\u0169\\\\u016B\\\\u016D\\\\u016F\\\\u0171\\\\u0173\\\\u0175\\\\u0177\\\\u017A\\\\u017C\\\\u017E\\\\u017F\\\\u0180\\\\u0183\\\\u0185\\\\u0188\\\\u018C\\\\u018D\\\\u0192\\\\u0195\\\\u0199-\\\\u019B\\\\u019E\\\\u01A1\\\\u01A3\\\\u01A5\\\\u01A8\\\\u01AA\\\\u01AB\\\\u01AD\\\\u01B0\\\\u01B4\\\\u01B6\\\\u01B9\\\\u01BA\\\\u01BD-\\\\u01BF\\\\u01C6\\\\u01C9\\\\u01CC\\\\u01CE\\\\u01D0\\\\u01D2\\\\u01D4\\\\u01D6\\\\u01D8\\\\u01DA\\\\u01DC\\\\u01DD\\\\u01DF\\\\u01E1\\\\u01E3\\\\u01E5\\\\u01E7\\\\u01E9\\\\u01EB\\\\u01ED\\\\u01EF\\\\u01F0\\\\u01F3\\\\u01F5\\\\u01F9\\\\u01FB\\\\u01FD\\\\u01FF\\\\u0201\\\\u0203\\\\u0205\\\\u0207\\\\u0209\\\\u020B\\\\u020D\\\\u020F\\\\u0211\\\\u0213\\\\u0215\\\\u0217\\\\u0219\\\\u021B\\\\u021D\\\\u021F\\\\u0221\\\\u0223\\\\u0225\\\\u0227\\\\u0229\\\\u022B\\\\u022D\\\\u022F\\\\u0231\\\\u0233-\\\\u0239\\\\u023C\\\\u023F\\\\u0240\\\\u0242\\\\u0247\\\\u0249\\\\u024B\\\\u024D\\\\u024F\\\\u2C61\\\\u2C65\\\\u2C66\\\\u2C68\\\\u2C6A\\\\u2C6C\\\\u2C71\\\\u2C73\\\\u2C74\\\\u2C76-\\\\u2C7B\\\\uA723\\\\uA725\\\\uA727\\\\uA729\\\\uA72B\\\\uA72D\\\\uA72F-\\\\uA731\\\\uA733\\\\uA735\\\\uA737\\\\uA739\\\\uA73B\\\\uA73D\\\\uA73F\\\\uA741\\\\uA743\\\\uA745\\\\uA747\\\\uA749\\\\uA74B\\\\uA74D\\\\uA74F\\\\uA751\\\\uA753\\\\uA755\\\\uA757\\\\uA759\\\\uA75B\\\\uA75D\\\\uA75F\\\\uA761\\\\uA763\\\\uA765\\\\uA767\\\\uA769\\\\uA76B\\\\uA76D\\\\uA76F\\\\uA771-\\\\uA778\\\\uA77A\\\\uA77C\\\\uA77F\\\\uA781\\\\uA783\\\\uA785\\\\uA787\\\\uA78C\\\\uA78E\\\\uA791\\\\uA793-\\\\uA795\\\\uA797\\\\uA799\\\\uA79B\\\\uA79D\\\\uA79F\\\\uA7A1\\\\uA7A3\\\\uA7A5\\\\uA7A7\\\\uA7A9\\\\uA7AF\\\\uA7B5\\\\uA7B7\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E01\\\\u1E03\\\\u1E05\\\\u1E07\\\\u1E09\\\\u1E0B\\\\u1E0D\\\\u1E0F\\\\u1E11\\\\u1E13\\\\u1E15\\\\u1E17\\\\u1E19\\\\u1E1B\\\\u1E1D\\\\u1E1F\\\\u1E21\\\\u1E23\\\\u1E25\\\\u1E27\\\\u1E29\\\\u1E2B\\\\u1E2D\\\\u1E2F\\\\u1E31\\\\u1E33\\\\u1E35\\\\u1E37\\\\u1E39\\\\u1E3B\\\\u1E3D\\\\u1E3F\\\\u1E41\\\\u1E43\\\\u1E45\\\\u1E47\\\\u1E49\\\\u1E4B\\\\u1E4D\\\\u1E4F\\\\u1E51\\\\u1E53\\\\u1E55\\\\u1E57\\\\u1E59\\\\u1E5B\\\\u1E5D\\\\u1E5F\\\\u1E61\\\\u1E63\\\\u1E65\\\\u1E67\\\\u1E69\\\\u1E6B\\\\u1E6D\\\\u1E6F\\\\u1E71\\\\u1E73\\\\u1E75\\\\u1E77\\\\u1E79\\\\u1E7B\\\\u1E7D\\\\u1E7F\\\\u1E81\\\\u1E83\\\\u1E85\\\\u1E87\\\\u1E89\\\\u1E8B\\\\u1E8D\\\\u1E8F\\\\u1E91\\\\u1E93\\\\u1E95-\\\\u1E9D\\\\u1E9F\\\\u1EA1\\\\u1EA3\\\\u1EA5\\\\u1EA7\\\\u1EA9\\\\u1EAB\\\\u1EAD\\\\u1EAF\\\\u1EB1\\\\u1EB3\\\\u1EB5\\\\u1EB7\\\\u1EB9\\\\u1EBB\\\\u1EBD\\\\u1EBF\\\\u1EC1\\\\u1EC3\\\\u1EC5\\\\u1EC7\\\\u1EC9\\\\u1ECB\\\\u1ECD\\\\u1ECF\\\\u1ED1\\\\u1ED3\\\\u1ED5\\\\u1ED7\\\\u1ED9\\\\u1EDB\\\\u1EDD\\\\u1EDF\\\\u1EE1\\\\u1EE3\\\\u1EE5\\\\u1EE7\\\\u1EE9\\\\u1EEB\\\\u1EED\\\\u1EEF\\\\u1EF1\\\\u1EF3\\\\u1EF5\\\\u1EF7\\\\u1EF9\\\\u1EFB\\\\u1EFD\\\\u1EFFёа-яәөүҗңһα-ωάέίόώήύа-щюяіїєґѓѕјљњќѐѝ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F\\\\\\'\"”“`‘´’‚,„»«「」『』（）〔〕【】《》〈〉])\\\\.(?=[A-Z\\\\uFF21-\\\\uFF3A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00DE\\\\u0100\\\\u0102\\\\u0104\\\\u0106\\\\u0108\\\\u010A\\\\u010C\\\\u010E\\\\u0110\\\\u0112\\\\u0114\\\\u0116\\\\u0118\\\\u011A\\\\u011C\\\\u011E\\\\u0120\\\\u0122\\\\u0124\\\\u0126\\\\u0128\\\\u012A\\\\u012C\\\\u012E\\\\u0130\\\\u0132\\\\u0134\\\\u0136\\\\u0139\\\\u013B\\\\u013D\\\\u013F\\\\u0141\\\\u0143\\\\u0145\\\\u0147\\\\u014A\\\\u014C\\\\u014E\\\\u0150\\\\u0152\\\\u0154\\\\u0156\\\\u0158\\\\u015A\\\\u015C\\\\u015E\\\\u0160\\\\u0162\\\\u0164\\\\u0166\\\\u0168\\\\u016A\\\\u016C\\\\u016E\\\\u0170\\\\u0172\\\\u0174\\\\u0176\\\\u0178\\\\u0179\\\\u017B\\\\u017D\\\\u0181\\\\u0182\\\\u0184\\\\u0186\\\\u0187\\\\u0189-\\\\u018B\\\\u018E-\\\\u0191\\\\u0193\\\\u0194\\\\u0196-\\\\u0198\\\\u019C\\\\u019D\\\\u019F\\\\u01A0\\\\u01A2\\\\u01A4\\\\u01A6\\\\u01A7\\\\u01A9\\\\u01AC\\\\u01AE\\\\u01AF\\\\u01B1-\\\\u01B3\\\\u01B5\\\\u01B7\\\\u01B8\\\\u01BC\\\\u01C4\\\\u01C7\\\\u01CA\\\\u01CD\\\\u01CF\\\\u01D1\\\\u01D3\\\\u01D5\\\\u01D7\\\\u01D9\\\\u01DB\\\\u01DE\\\\u01E0\\\\u01E2\\\\u01E4\\\\u01E6\\\\u01E8\\\\u01EA\\\\u01EC\\\\u01EE\\\\u01F1\\\\u01F4\\\\u01F6-\\\\u01F8\\\\u01FA\\\\u01FC\\\\u01FE\\\\u0200\\\\u0202\\\\u0204\\\\u0206\\\\u0208\\\\u020A\\\\u020C\\\\u020E\\\\u0210\\\\u0212\\\\u0214\\\\u0216\\\\u0218\\\\u021A\\\\u021C\\\\u021E\\\\u0220\\\\u0222\\\\u0224\\\\u0226\\\\u0228\\\\u022A\\\\u022C\\\\u022E\\\\u0230\\\\u0232\\\\u023A\\\\u023B\\\\u023D\\\\u023E\\\\u0241\\\\u0243-\\\\u0246\\\\u0248\\\\u024A\\\\u024C\\\\u024E\\\\u2C60\\\\u2C62-\\\\u2C64\\\\u2C67\\\\u2C69\\\\u2C6B\\\\u2C6D-\\\\u2C70\\\\u2C72\\\\u2C75\\\\u2C7E\\\\u2C7F\\\\uA722\\\\uA724\\\\uA726\\\\uA728\\\\uA72A\\\\uA72C\\\\uA72E\\\\uA732\\\\uA734\\\\uA736\\\\uA738\\\\uA73A\\\\uA73C\\\\uA73E\\\\uA740\\\\uA742\\\\uA744\\\\uA746\\\\uA748\\\\uA74A\\\\uA74C\\\\uA74E\\\\uA750\\\\uA752\\\\uA754\\\\uA756\\\\uA758\\\\uA75A\\\\uA75C\\\\uA75E\\\\uA760\\\\uA762\\\\uA764\\\\uA766\\\\uA768\\\\uA76A\\\\uA76C\\\\uA76E\\\\uA779\\\\uA77B\\\\uA77D\\\\uA77E\\\\uA780\\\\uA782\\\\uA784\\\\uA786\\\\uA78B\\\\uA78D\\\\uA790\\\\uA792\\\\uA796\\\\uA798\\\\uA79A\\\\uA79C\\\\uA79E\\\\uA7A0\\\\uA7A2\\\\uA7A4\\\\uA7A6\\\\uA7A8\\\\uA7AA-\\\\uA7AE\\\\uA7B0-\\\\uA7B4\\\\uA7B6\\\\uA7B8\\\\u1E00\\\\u1E02\\\\u1E04\\\\u1E06\\\\u1E08\\\\u1E0A\\\\u1E0C\\\\u1E0E\\\\u1E10\\\\u1E12\\\\u1E14\\\\u1E16\\\\u1E18\\\\u1E1A\\\\u1E1C\\\\u1E1E\\\\u1E20\\\\u1E22\\\\u1E24\\\\u1E26\\\\u1E28\\\\u1E2A\\\\u1E2C\\\\u1E2E\\\\u1E30\\\\u1E32\\\\u1E34\\\\u1E36\\\\u1E38\\\\u1E3A\\\\u1E3C\\\\u1E3E\\\\u1E40\\\\u1E42\\\\u1E44\\\\u1E46\\\\u1E48\\\\u1E4A\\\\u1E4C\\\\u1E4E\\\\u1E50\\\\u1E52\\\\u1E54\\\\u1E56\\\\u1E58\\\\u1E5A\\\\u1E5C\\\\u1E5E\\\\u1E60\\\\u1E62\\\\u1E64\\\\u1E66\\\\u1E68\\\\u1E6A\\\\u1E6C\\\\u1E6E\\\\u1E70\\\\u1E72\\\\u1E74\\\\u1E76\\\\u1E78\\\\u1E7A\\\\u1E7C\\\\u1E7E\\\\u1E80\\\\u1E82\\\\u1E84\\\\u1E86\\\\u1E88\\\\u1E8A\\\\u1E8C\\\\u1E8E\\\\u1E90\\\\u1E92\\\\u1E94\\\\u1E9E\\\\u1EA0\\\\u1EA2\\\\u1EA4\\\\u1EA6\\\\u1EA8\\\\u1EAA\\\\u1EAC\\\\u1EAE\\\\u1EB0\\\\u1EB2\\\\u1EB4\\\\u1EB6\\\\u1EB8\\\\u1EBA\\\\u1EBC\\\\u1EBE\\\\u1EC0\\\\u1EC2\\\\u1EC4\\\\u1EC6\\\\u1EC8\\\\u1ECA\\\\u1ECC\\\\u1ECE\\\\u1ED0\\\\u1ED2\\\\u1ED4\\\\u1ED6\\\\u1ED8\\\\u1EDA\\\\u1EDC\\\\u1EDE\\\\u1EE0\\\\u1EE2\\\\u1EE4\\\\u1EE6\\\\u1EE8\\\\u1EEA\\\\u1EEC\\\\u1EEE\\\\u1EF0\\\\u1EF2\\\\u1EF4\\\\u1EF6\\\\u1EF8\\\\u1EFA\\\\u1EFC\\\\u1EFEЁА-ЯӘӨҮҖҢҺΑ-ΩΆΈΊΌΏΉΎА-ЩЮЯІЇЄҐЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F\\\\\\'\"”“`‘´’‚,„»«「」『』（）〔〕【】《》〈〉])',\n",
       " '(?<=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F]),(?=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F])',\n",
       " '(?<=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F0-9])(?:-|–|—|--|---|——|~)(?=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F])',\n",
       " '(?<=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F0-9])[:<>=/](?=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F])']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.infixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27be3791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.infixes), len([pattern for pattern in nlp.Defaults.infixes if not re.search(pattern, \"xx-xx\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb82c71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(?<=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F0-9])(?:-|–|—|--|---|——|~)(?=[A-Za-z\\\\uFF21-\\\\uFF3A\\\\uFF41-\\\\uFF5A\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u00FF\\\\u0100-\\\\u017F\\\\u0180-\\\\u01BF\\\\u01C4-\\\\u024F\\\\u2C60-\\\\u2C7B\\\\u2C7E\\\\u2C7F\\\\uA722-\\\\uA76F\\\\uA771-\\\\uA787\\\\uA78B-\\\\uA78E\\\\uA790-\\\\uA7B9\\\\uA7FA\\\\uAB30-\\\\uAB5A\\\\uAB60-\\\\uAB64\\\\u0250-\\\\u02AF\\\\u1D00-\\\\u1D25\\\\u1D6B-\\\\u1D77\\\\u1D79-\\\\u1D9A\\\\u1E00-\\\\u1EFFёа-яЁА-ЯәөүҗңһӘӨҮҖҢҺα-ωάέίόώήύΑ-ΩΆΈΊΌΏΉΎа-щюяіїєґА-ЩЮЯІЇЄҐѓѕјљњќѐѝЃЅЈЉЊЌЀЍ\\\\u1200-\\\\u137F\\\\u0980-\\\\u09FF\\\\u0591-\\\\u05F4\\\\uFB1D-\\\\uFB4F\\\\u0620-\\\\u064A\\\\u066E-\\\\u06D5\\\\u06E5-\\\\u06FF\\\\u0750-\\\\u077F\\\\u08A0-\\\\u08BD\\\\uFB50-\\\\uFBB1\\\\uFBD3-\\\\uFD3D\\\\uFD50-\\\\uFDC7\\\\uFDF0-\\\\uFDFB\\\\uFE70-\\\\uFEFC\\\\U0001EE00-\\\\U0001EEBB\\\\u0D80-\\\\u0DFF\\\\u0900-\\\\u097F\\\\u0C80-\\\\u0CFF\\\\u0B80-\\\\u0BFF\\\\u0C00-\\\\u0C7F\\\\uAC00-\\\\uD7AF\\\\u1100-\\\\u11FF\\\\u3040-\\\\u309F\\\\u30A0-\\\\u30FFー\\\\u4E00-\\\\u62FF\\\\u6300-\\\\u77FF\\\\u7800-\\\\u8CFF\\\\u8D00-\\\\u9FFF\\\\u3400-\\\\u4DBF\\\\U00020000-\\\\U000215FF\\\\U00021600-\\\\U000230FF\\\\U00023100-\\\\U000245FF\\\\U00024600-\\\\U000260FF\\\\U00026100-\\\\U000275FF\\\\U00027600-\\\\U000290FF\\\\U00029100-\\\\U0002A6DF\\\\U0002A700-\\\\U0002B73F\\\\U0002B740-\\\\U0002B81F\\\\U0002B820-\\\\U0002CEAF\\\\U0002CEB0-\\\\U0002EBEF\\\\u2E80-\\\\u2EFF\\\\u2F00-\\\\u2FDF\\\\u2FF0-\\\\u2FFF\\\\u3000-\\\\u303F\\\\u31C0-\\\\u31EF\\\\u3200-\\\\u32FF\\\\u3300-\\\\u33FF\\\\uF900-\\\\uFAFF\\\\uFE30-\\\\uFE4F\\\\U0001F200-\\\\U0001F2FF\\\\U0002F800-\\\\U0002FA1F])']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pattern for pattern in nlp.Defaults.infixes if re.search(pattern, \"xx-xx\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69160fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low|-|carb|#|food|#|eat|-|smart|.|_|url|_|;-)|😋|👍|"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75708325",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = custom_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82c5b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low-carb|#food|#eat-smart|.|_url_|;-)|😋|👍|"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419f688",
   "metadata": {},
   "source": [
    "### 4.3 Blueprint: Working with stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00a328b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Dear Ryan, we need to sit down and talk. Regards, Pete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92f55512",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9335edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop = [t for t in doc if not t.is_stop and not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1af3910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dear, Ryan, need, sit, talk, Regards, Pete]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f395105",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58174312",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[\"down\"].is_stop = False\n",
    "nlp.vocab[\"Dear\"].is_stop = True\n",
    "nlp.vocab[\"Regards\"].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5b0d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d26a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ryan, need, sit, down, talk, Pete]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in doc if not t.is_stop and not t.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d27fe6",
   "metadata": {},
   "source": [
    "### 4.4 Blueprint: Extracting lemmas based on part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "88b3f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "78b7f31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My best friend Ryan Peters likes fancy adventure games."
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e63fe429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my|good|friend|Ryan|Peters|like|fancy|adventure|game|.\n"
     ]
    }
   ],
   "source": [
    "print(*[t.lemma_ for t in doc], sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea950ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My PRON PRP$\n",
      "best ADJ JJS\n",
      "friend NOUN NN\n",
      "Ryan PROPN NNP\n",
      "Peters PROPN NNP\n",
      "likes VERB VBZ\n",
      "fancy ADJ JJ\n",
      "adventure NOUN NN\n",
      "games NOUN NNS\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for i in doc:\n",
    "    print(i, i.pos_, i.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e076458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[friend, Ryan, Peters, adventure, games]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [t for t in doc if t.pos_ in [\"NOUN\", \"PROPN\"]]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56340506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8edcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = textacy.extract.words(\n",
    "    doc, \n",
    "    filter_stops=True, # stopwords\n",
    "    filter_punct=True, # punctuation\n",
    "    filter_nums=True, # numbers\n",
    "    include_pos=['Adj', 'NOUN'], # Include Part-of-Speech\n",
    "    exclude_pos=None, # Exclude Part-of-Speech\n",
    "    min_freq=1 # minimum frequency of words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2df4698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best|friend|fancy|adventure|games\n"
     ]
    }
   ],
   "source": [
    "print(*[t for t in tokens], sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a5ef46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t .lemma_ for t in textacy.extract.words(doc, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a92483a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = extract_lemmas(doc, include_pos=[\"Adj\", \"NOUN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "06312a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'friend', 'fancy', 'adventure', 'game']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e779fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good|friend|fancy|adventure|game\n"
     ]
    }
   ],
   "source": [
    "print(*lemmas, sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9749f7",
   "metadata": {},
   "source": [
    "### 4.5 Blueprint: Extracting Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "48aa834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My best friend Ryan Peters likes fancy adventure games.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "be4868e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80b6a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My best friend Ryan Peters likes fancy adventure games."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "70bf0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\"POS:ADJ POS:NOUN:+\"]\n",
    "spans = textacy.extract.token_matches(doc, patterns=patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "045cc497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object token_matches at 0x7f14d2fd4190>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.extract.matches.token_matches(doc, patterns=patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a33dbaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good friend|fancy adventure|fancy adventure game\n"
     ]
    }
   ],
   "source": [
    "print(*[s.lemma_ for s in spans], sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4775dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_phrases(doc, preceeding_pos=[\"Noun\"], sep=\"_\"):\n",
    "    patterns=[]\n",
    "    for pos in preceeding_pos:\n",
    "        patterns.append(f\"POS:{pos} POS:NOUN:+\")\n",
    "    spans = textacy.extract.token_matches(doc, patterns=patterns)\n",
    "    return [sep.join([t.lemma_ for t in s]) for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "48848b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_friend|fancy_adventure|fancy_adventure_game|adventure_game\n"
     ]
    }
   ],
   "source": [
    "print(*extract_noun_phrases(doc, preceeding_pos=[\"NOUN\", \"ADJ\"]), sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab6859",
   "metadata": {},
   "source": [
    "### 4.6 Blueprint: Extracting Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "df583191",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"James O'Neill, chairman of World Cargo Inc, lives in San Francisco.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9459a443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(James O'Neill, PERSON)\n",
      "(World Cargo Inc, ORG)\n",
      "(San Francisco, GPE)\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f\"({ent.text}, {ent.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6fb9bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8c87f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    James O'Neill\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", chairman of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World Cargo Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3fefe497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(doc, include_types=None, sep=\"_\"):\n",
    "    ents = textacy.extract.entities(\n",
    "        doc,\n",
    "        include_types=include_types,\n",
    "        exclude_types=None,\n",
    "        drop_determiners=True,\n",
    "        min_freq=1\n",
    "    )\n",
    "    return [sep.join([t.lemma_ for t in e])+\"/\"+e.label_ for e in ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1ccc56ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"James_O'Neill/PERSON\", 'World_Cargo_Inc/ORG', 'San_Francisco/GPE']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517259e",
   "metadata": {},
   "source": [
    "## 5. Feature Extraction on a Large Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62afc8b4",
   "metadata": {},
   "source": [
    "### 5.1 Blueprint: Combine Extraction Function into One Function to Get it All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7d273db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nlp(doc):\n",
    "    return {\n",
    "        'lemmas': extract_lemmas(doc, exclude_pos=[\"PART\", \"PUNCT\", \"DET\", \"PRON\", \"SYM\", \"SPACE\"], filter_stops=False),\n",
    "        'adj_verbs': extract_lemmas(doc, include_pos=[\"ADJ\", \"VERB\"]),\n",
    "        'nouns': extract_lemmas(doc, include_pos=[\"NOUN\", \"PROPN\"]),\n",
    "        'noun_phrases': extract_noun_phrases(doc, preceeding_pos=[\"NOUN\"]),\n",
    "        'adj_noun_phrases': extract_noun_phrases(doc, preceeding_pos=[\"ADJ\"]),\n",
    "        'entities': extract_entities(doc, [\"PERSON\", \"ORG\", \"GPE\", \"LOC\"])\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cbc1dc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lemmas': ['good',\n",
       "  'friend',\n",
       "  'Ryan',\n",
       "  'Peters',\n",
       "  'like',\n",
       "  'fancy',\n",
       "  'adventure',\n",
       "  'game'],\n",
       " 'adj_verbs': ['good', 'like', 'fancy'],\n",
       " 'nouns': ['friend', 'Ryan', 'Peters', 'adventure', 'game'],\n",
       " 'noun_phrases': ['adventure_game'],\n",
       " 'adj_noun_phrases': ['good_friend',\n",
       "  'fancy_adventure',\n",
       "  'fancy_adventure_game'],\n",
       " 'entities': ['Ryan_Peters/PERSON']}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_nlp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e91bbd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: ['good', 'friend', 'Ryan', 'Peters', 'like', 'fancy', 'adventure', 'game']\n",
      "adj_verbs: ['good', 'like', 'fancy']\n",
      "nouns: ['friend', 'Ryan', 'Peters', 'adventure', 'game']\n",
      "noun_phrases: ['adventure_game']\n",
      "adj_noun_phrases: ['good_friend', 'fancy_adventure', 'fancy_adventure_game']\n",
      "entities: ['Ryan_Peters/PERSON']\n"
     ]
    }
   ],
   "source": [
    "for col, values in extract_nlp(doc).items():\n",
    "    print(f\"{col}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "51e2abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_columns = list(extract_nlp(nlp.make_doc('')).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9af7eaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lemmas',\n",
       " 'adj_verbs',\n",
       " 'nouns',\n",
       " 'noun_phrases',\n",
       " 'adj_noun_phrases',\n",
       " 'entities']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533eecbd",
   "metadata": {},
   "source": [
    "### 5. 2 Blueprint: Usinf spaCy on a Large Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573d9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
